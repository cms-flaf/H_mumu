
[meta]
results_dir = "/afs/cern.ch/user/a/ayeagle/H_mumu/Studies/DNN/results"
use_cuda = true

[dataloader]
# Events selection
selection_cut = "(Signal_Fit) & (j1_pt != -1000) & (j2_pt != -1000)"
# Event splitting (traing_size is what's left)
valid_size = 0.25
test_size = 0.0
# Input vector def
columns_config = '/afs/cern.ch/user/a/ayeagle/H_mumu/Studies/DNN/ds_setup/vbfnet_general.yaml'
signal_types = ['VBFH']
# Binary or multiclass
classification = 'binary'          
# Per file stitching
file_stitching = ''
renorm_inputs = 'gauss'


[preprocess]
# Reweigh/rebalance options
uniform_train_weight = false       # If true, all train weights (prenorm) = 1
zero_negative_weights = true       # Remove the effect of negative weights for training only
equalize_class_weights = true      # Sets each class weight to be equal (training only!)
renorm_inputs = 'gauss'            # Apply some scaling/renorm to the input columns. Can be 'no', 'linear', or 'gauss'
downsample_upweight = false        # Whether or not to downsample majority classes
target_ratio = 10                  # New N_{majority_class}/N_{minority_class} ratio (if using downsample)
use_mass_resolution = false

[kfold]
k = 4

[network]  
# Hidden layers only
# Input layer size pulled from the used columns
layer_list = [32, 32, 32]
dropout = 0

[training]
# batch_size = 0 means use the whole set (1 batch per epoch)
batch_size = 2500
epochs = 700
early_stop = true
early_threshold = 0
patience = 75
label_smoothing = 0.0

[optimizer]
algo = "Adam"   # Currently, SGD and Adam are supported
lr = 1e-04
weight_decay = 0.0
#momentum = 0.7
#dampening = 0.2

[testing]
# Number of bins for all histograms
n_bins = 12


